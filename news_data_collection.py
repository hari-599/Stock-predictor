# -*- coding: utf-8 -*-
"""News_data_collection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hAfUaj9USZ3CJYydByRJAUc3RE_qz0i0

## **DATA COLLECTION**
"""

import pandas as pd
import numpy as np
import requests
import json
import csv
import datetime
!pip install pandas_datareader
!pip install yfinance

"""In the collection stage, it used to collect newses based on the ticker keyword. It used 'Alphavantage' for the collection of news."""

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=AAPL&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/apple.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'AAPL'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=MSFT&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/Data_msc/msft.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'MSFT'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=TSLA&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/Data_msc/tsla.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'TSLA'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=GOOGL&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/Data_msc/googl.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'GOOGL'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=GOOG&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/Data_msc/goog.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'GOOG'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=NVDA&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/Data_msc/nvda.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'NVDA'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=AMD&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/Data_msc/amd.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'AMD'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=PFE&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/Data_msc/pfe.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'PFE'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")

apikey = "9A8S2NN68B7CMXLW"
base_url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=JNJ&time_from={start_time}&time_to={end_time}&limit=1000&apikey={apikey}'
csv_name = '/content/drive/My Drive/Data_msc/jnj.csv'
# Define the start and end dates of the desired period
start_date = datetime.datetime.strptime('2022-01-01', '%Y-%m-%d')
end_date = datetime.datetime.strptime('2023-06-01', '%Y-%m-%d')
current_date = start_date

with open(csv_name, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Title", "Description", "Date", 'ticker', 'topic'])

    while current_date <= end_date:
        # Format current date as per the API requirement
        formatted_date = current_date.strftime('%Y%m%d')

        # Construct the API URL with the current interval
        start_time = f"{formatted_date}T0130"
        end_date = current_date + datetime.timedelta(days=60)
        formatted_end_date = end_date.strftime('%Y%m%d')
        start_time = f"{formatted_date}T0130"
        end_time = f"{formatted_end_date}T0130"
        url = base_url.format(start_time=start_time, end_time=end_time, apikey=apikey)

        # Make the API call
        response = requests.get(url)
        data = response.json()

        if 'feed' in data:
          articles=data['feed']
          for article in articles:
              title = article["title"]
              description = article["summary"]
              date = article["time_published"].split("T")[0]
              ticker = 'JNJ'
              topics = data["feed"][0]["topics"]
              topic_with_highest_score = max(topics, key=lambda x: float(x["relevance_score"]))
              topic = topic_with_highest_score["topic"]
              writer.writerow([title, description, date, ticker, topic])

          # Increment current date by one month
          current_date = current_date + datetime.timedelta(days=60)

        else:
          print(f"No news articles found for date {formatted_date}")
        if current_date > end_date:
          break

print("Data written to CSV successfully.")